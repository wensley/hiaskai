export default {
  'benchmark.actions.delete': 'Delete Benchmark',
  'benchmark.actions.delete.confirm':
    'Are you sure you want to delete this benchmark? Related datasets and evaluation records will also be deleted.',
  'benchmark.actions.edit': 'Edit Benchmark',
  'benchmark.actions.export': 'Export',
  'benchmark.card.bestScore': 'Best',
  'benchmark.card.caseCount': '{{count}} cases',
  'benchmark.card.datasetCount': '{{count}} datasets',
  'benchmark.card.empty': 'No evaluations yet',
  'benchmark.card.emptyHint': 'Create a new evaluation from the benchmark detail page',
  'benchmark.card.importDataset': 'Import Dataset',
  'benchmark.card.noDataset': 'No datasets yet',
  'benchmark.card.noDatasetHint': 'Import a dataset to start evaluating',
  'benchmark.card.noRecentRuns': 'No recent evaluations to display',
  'benchmark.card.recentRuns': 'Recent Evaluations',
  'benchmark.card.runCount': '{{count}} evals',
  'benchmark.card.startFirst': 'Start First Evaluation',
  'benchmark.card.viewAll': 'View all {{count}}',
  'benchmark.create.confirm': 'Create',
  'benchmark.create.description.label': 'Description',
  'benchmark.create.description.placeholder': 'Benchmark description (optional)',
  'benchmark.create.error': 'Failed to create benchmark',
  'benchmark.create.identifier.label': 'Identifier',
  'benchmark.create.identifier.placeholder': 'benchmark-identifier',
  'benchmark.create.identifierRequired': 'Please enter an identifier',
  'benchmark.create.name.label': 'Name',
  'benchmark.create.name.placeholder': 'Enter benchmark name',
  'benchmark.create.nameRequired': 'Please enter a benchmark name',
  'benchmark.create.success': 'Benchmark created successfully',
  'benchmark.create.tags.label': 'Tags',
  'benchmark.create.tags.placeholder': 'Add tags, separate with comma or space',
  'benchmark.create.title': 'Create Benchmark',
  'benchmark.edit.confirm': 'Save',
  'benchmark.edit.error': 'Failed to update benchmark',
  'benchmark.edit.success': 'Benchmark updated successfully',
  'benchmark.edit.title': 'Edit Benchmark',
  'benchmark.detail.backToOverview': 'Back to Overview',
  'benchmark.detail.datasetCount':
    '{{count}} dataset{{count, plural, one {} other {s}}} in this benchmark',
  'benchmark.detail.runCount':
    '{{count}} evaluation run{{count, plural, one {} other {s}}} on this benchmark',
  'benchmark.detail.stats.bestScore': 'Best Score',
  'benchmark.detail.stats.cases': 'Cases',
  'benchmark.detail.stats.datasets': 'Datasets',
  'benchmark.detail.stats.runs': 'Runs',
  'benchmark.detail.stats.tags': 'Tags',
  'benchmark.detail.stats.addFirstDataset': 'Click to add first dataset',
  'benchmark.detail.stats.avgCost': 'Avg Cost',
  'benchmark.detail.stats.bestPerformance':
    'Best performance by {{agent}} with {{passRate}}% pass rate',
  'benchmark.detail.stats.avgDuration': 'Avg Duration',
  'benchmark.detail.stats.basedOnLastNRuns': 'Based on last {{count}} runs',
  'benchmark.detail.stats.dataScale': 'Data Scale',
  'benchmark.detail.stats.needSetup': 'Setup Required',
  'benchmark.detail.stats.noEvalRecord': 'No evaluation records yet',
  'benchmark.detail.stats.perRun': '/ Run',
  'benchmark.detail.stats.topAgents': 'Top Agents',
  'benchmark.detail.stats.totalCases': 'Total Cases',
  'benchmark.detail.stats.waiting': 'Waiting...',
  'benchmark.detail.tabs.data': 'Data',
  'benchmark.detail.tabs.datasets': 'Datasets',
  'benchmark.detail.tabs.runs': 'Runs',
  'benchmark.empty': 'No benchmarks yet. Create one to get started.',

  'common.cancel': 'Cancel',
  'common.create': 'Create',
  'common.delete': 'Delete',
  'common.edit': 'Edit',
  'common.later': 'Later',
  'common.next': 'Next',
  'common.update': 'Update',

  'caseDetail.actual': 'Actual Output',
  'caseDetail.chatArea.title': 'Conversation',
  'caseDetail.cost': 'Cost',
  'caseDetail.difficulty': 'Difficulty',
  'caseDetail.duration': 'Duration',
  'caseDetail.expected': 'Expected Output',
  'caseDetail.failureReason': 'Failure Reason',
  'caseDetail.input': 'Input',
  'caseDetail.judgeComment': 'Judge Comment',
  'caseDetail.resources': 'Resources',
  'caseDetail.score': 'Score',
  'caseDetail.completionReason': 'Status',
  'caseDetail.section.runtime': 'Runtime',
  'caseDetail.section.scoring': 'Scoring Details',
  'caseDetail.section.testCase': 'Test Case',
  'caseDetail.steps': 'Steps',
  'caseDetail.threads.attempt': 'Trajectory #{{number}}',
  'caseDetail.tokens': 'Token Usage',

  'dataset.actions.addDataset': 'Add Dataset',
  'dataset.actions.import': 'Import Data',
  'dataset.actions.importDataset': 'Import Dataset',
  'dataset.delete.confirm':
    'Are you sure you want to delete this dataset? All test cases in it will also be deleted.',
  'dataset.delete.error': 'Failed to delete dataset',
  'dataset.delete.success': 'Dataset deleted successfully',
  'dataset.create.description.label': 'Description',
  'dataset.create.description.placeholder': 'Dataset description (optional)',
  'dataset.create.error': 'Failed to create dataset',
  'dataset.create.identifier.label': 'Identifier',
  'dataset.create.identifier.placeholder': 'dataset-identifier',
  'dataset.create.identifierRequired': 'Please enter an identifier',
  'dataset.create.importNow': 'Would you like to import data now?',
  'dataset.create.name.label': 'Dataset Name',
  'dataset.create.name.placeholder': 'Enter dataset name',
  'dataset.create.nameRequired': 'Please enter a dataset name',
  'dataset.create.preset.label': 'Dataset Preset',
  'dataset.create.success': 'Dataset created successfully',
  'dataset.create.successTitle': 'Dataset Created',
  'dataset.create.title': 'Create Dataset',
  'dataset.edit.error': 'Failed to update dataset',
  'dataset.edit.success': 'Dataset updated successfully',
  'dataset.edit.title': 'Edit Dataset',
  'dataset.empty': 'No datasets',
  'dataset.empty.description': 'Import a dataset to start building this benchmark',
  'dataset.empty.title': 'No datasets yet',
  'dataset.import.choices': 'Choices',
  'dataset.import.choicesDesc': 'Multiple-choice options',
  'dataset.import.confirm': 'Import',
  'dataset.import.category': 'Category',
  'dataset.import.categoryDesc': 'Classification label for grouping',
  'dataset.import.error': 'Failed to import dataset',
  'dataset.import.expected': 'Expected Answer',
  'dataset.import.expectedDelimiter': 'Answer Delimiter',
  'dataset.import.expectedDelimiter.desc': 'Answer delimiter',
  'dataset.import.expectedDelimiter.placeholder': 'e.g. | or ,',
  'dataset.import.expectedDesc': 'Correct answer to compare against',
  'dataset.import.fieldMapping': 'Field Mapping',
  'dataset.import.fieldMapping.desc': '"Input" column is required',
  'dataset.import.hideSkipped': 'Hide skipped columns',
  'dataset.import.ignore': 'Skip',
  'dataset.import.ignoreDesc': 'Do not import this column',
  'dataset.import.input': 'Input',
  'dataset.import.inputDesc': 'Question or prompt sent to model',
  'dataset.import.metadata': 'Metadata',
  'dataset.import.metadataDesc': 'Extra info, stored as-is',
  'dataset.import.next': 'Next',
  'dataset.import.parseError': 'Failed to parse file',
  'dataset.import.parsing': 'Parsing file...',
  'dataset.import.prev': 'Previous',
  'dataset.import.preview': 'Data Preview',
  'dataset.import.preview.desc': 'Confirm the mapping is correct, then import.',
  'dataset.import.preview.rows': '{{count}} rows total',
  'dataset.import.sortOrder': 'Item Number',
  'dataset.import.sortOrderDesc': 'Question/item ID for reference',
  'dataset.import.step.mapping': 'Map Fields',
  'dataset.import.step.preview': 'Preview',
  'dataset.import.step.upload': 'Upload File',
  'dataset.import.success': 'Successfully imported {{count}} test cases',
  'dataset.import.title': 'Import Dataset',
  'dataset.import.upload.hint': 'Supports CSV, XLSX, JSON, JSONL',
  'dataset.import.upload.text': 'Click or drag file here to upload',
  'dataset.import.uploading': 'Uploading...',
  'dataset.detail.backToBenchmark': 'Back to Benchmark',
  'dataset.detail.caseCount': '{{count}} test case{{count, plural, one {} other {s}}}',
  'dataset.detail.addRun': 'New Run',
  'dataset.detail.relatedRuns': 'Related Runs ({{count}})',
  'dataset.detail.testCases': 'Test Cases',
  'dataset.detail.viewDetail': 'View Details',
  'dataset.switchDataset': 'Switch Dataset',

  'dataset.evalMode.hint':
    'Default eval mode for the dataset, can be overridden at test case level',

  'difficulty.easy': 'Easy',
  'difficulty.hard': 'Hard',
  'difficulty.medium': 'Medium',

  'evalMode.contains': 'Contains Match',
  'evalMode.contains.desc': 'Output must contain the expected text',
  'evalMode.equals': 'Exact Match',
  'evalMode.equals.desc': 'Output must be exactly the same as expected',
  'evalMode.label': 'Eval Mode',
  'evalMode.llm-rubric': 'LLM Judge',
  'evalMode.llm-rubric.desc': 'Use LLM to evaluate output quality',
  'evalMode.placeholder': 'Select eval mode',
  'evalMode.prompt.label': 'Judge Prompt',
  'evalMode.prompt.placeholder': 'Enter the evaluation criteria or prompt for LLM judge',
  'evalMode.rubric': 'Rubric Scoring',
  'evalMode.rubric.desc': 'Score output using benchmark rubrics with weighted criteria',

  'overview.createBenchmark': 'Create Benchmark',
  'overview.importDataset': 'Import Dataset',
  'overview.subtitle': 'Benchmark and evaluate your AI agents across datasets',
  'overview.title': 'Evaluation Lab',

  'run.actions.abort': 'Abort',
  'run.actions.edit': 'Edit',
  'run.actions.abort.confirm': 'Are you sure you want to abort this evaluation?',
  'run.actions.create': 'New Evaluation',
  'run.actions.delete': 'Delete',
  'run.actions.delete.confirm': 'Are you sure you want to delete this evaluation?',
  'run.actions.retryCase': 'Retry',
  'run.actions.retryErrors': 'Retry Errors',
  'run.actions.retryErrors.confirm':
    'This will re-run all error and timeout cases. Passed and failed cases will not be affected.',
  'run.actions.run': 'Run',
  'run.edit.error': 'Failed to update evaluation',
  'run.edit.success': 'Evaluation updated successfully',
  'run.edit.title': 'Edit Evaluation',
  'run.idle.hint': 'Click Start to begin evaluation',
  'run.pending.hint': 'Evaluation is queued, waiting to start...',
  'run.running.hint': 'Evaluation is running, results will appear shortly...',

  'run.filter.active': 'Active',
  'run.filter.empty': 'No runs match the current filter.',

  'run.empty.description': 'Start your first evaluation run on this dataset',
  'run.empty.descriptionBenchmark': 'Start your first evaluation run on this benchmark',
  'run.empty.title': 'No runs yet',
  'run.config.agentId': 'Agent',
  'run.config.concurrency': 'Concurrency',
  'run.config.maxSteps': 'Max Steps',
  'run.config.maxSteps.hint': 'Each LLM call or tool call by the agent counts as 1 step',
  'run.config.judgeModel': 'Judge Model',
  'run.config.model': 'Model',
  'run.config.temperature': 'Temperature',
  'run.config.k': 'Executions (K)',
  'run.config.k.hint': 'Run each test case {{k}} times for pass@{{k}}/pass^{{k}} metrics',
  'run.config.timeout': 'Timeout',
  'run.config.timeout.unit': 'min',
  'run.create.advanced': 'Advanced Settings',
  'run.create.agent': 'Agent',
  'run.create.agent.placeholder': 'Select an agent',
  'run.create.agent.required': 'Please select an agent',
  'run.create.caseCount': '{{count}} cases',
  'run.create.confirm': 'Create & Start',
  'run.create.createOnly': 'Create',
  'run.create.dataset': 'Dataset',
  'run.create.dataset.placeholder': 'Select a dataset',
  'run.create.dataset.required': 'Please select a dataset',
  'run.create.name': 'Run Name',
  'run.create.openAgent': 'Open agent in new window',
  'run.create.name.placeholder': 'Enter a name for this run',
  'run.create.name.required': 'Please enter a run name',
  'run.create.name.useTimestamp': 'Use current time as name',
  'run.create.title': 'New Evaluation',
  'run.create.titleWithDataset': 'New Evaluation on "{{dataset}}"',
  'run.actions.start': 'Start',
  'run.actions.start.confirm': 'Are you sure you want to start this evaluation?',
  'run.detail.agent': 'Agent',
  'run.detail.agent.none': 'Not specified',
  'run.detail.agent.unnamed': 'Unnamed Agent',
  'run.detail.backToBenchmark': 'Back to Benchmark',
  'run.detail.caseResults': 'Eval Details',
  'run.detail.report': 'Evaluation Summary',
  'run.detail.config': 'Evaluation Config',
  'run.detail.configSnapshot': 'Configuration Snapshot',
  'run.detail.dataset': 'Dataset',
  'run.detail.model': 'Model',
  'run.detail.overview': 'Overview',
  'run.detail.progress': 'Progress',
  'run.detail.progressCases': 'cases',
  'run.chart.duration': 'Duration (s)',
  'run.chart.error': 'Error',
  'run.chart.fail': 'Fail',
  'run.chart.latencyDistribution': 'Latency Distribution',
  'run.chart.latencyTokenDistribution': 'Latency / Token Distribution',
  'run.chart.pass': 'Pass',
  'run.chart.passFailError': 'Pass / Fail / Error',
  'run.chart.tokens': 'Tokens',
  'run.metrics.avgScore': 'Avg Score',
  'run.metrics.cost': 'Cost',
  'run.metrics.duration': 'Duration',
  'run.metrics.errorCases': 'Error',
  'run.metrics.evaluated': '{{count}} evaluated',
  'run.metrics.passRate': 'Pass Rate',
  'run.metrics.perCase': '/ case',
  'run.metrics.tokens': 'Tokens',
  'run.metrics.totalDuration': 'Cumulative',

  'sidebar.benchmarks': 'Benchmarks',
  'sidebar.dashboard': 'Dashboard',
  'sidebar.datasets': 'Datasets',
  'sidebar.runs': 'Runs',

  'run.status.aborted': 'Aborted',
  'run.status.completed': 'Completed',
  'run.status.error': 'Run Error',
  'run.status.failed': 'Failed',
  'run.status.idle': 'Idle',
  'run.status.pending': 'Pending',
  'run.status.running': 'Running',
  'run.status.timeout': 'Timeout',

  'table.columns.avgCost': 'Avg Cost',
  'table.columns.category': 'Category',
  'table.columns.cost': 'Cost',
  'table.columns.totalCost': 'Total Cost',
  'table.columns.difficulty': 'Difficulty',
  'table.columns.duration': 'Duration',
  'table.columns.evalMode': 'Eval Mode',
  'table.columns.expected': 'Expected Answer',
  'table.columns.input': 'Input',
  'table.columns.score': 'Score',
  'table.columns.steps': 'Steps',
  'table.columns.tokens': 'Tokens',
  'table.columns.status': 'Status',
  'table.columns.tags': 'Tags',

  'table.filter.all': 'All',
  'table.filter.error': 'Run Error',
  'table.filter.failed': 'Failed',
  'table.filter.passed': 'Passed',
  'table.filter.running': 'Running',
  'table.search.placeholder': 'Search cases...',
  'table.total': 'Total {{count}}',

  'testCase.actions.add': 'Add Test Case',
  'testCase.actions.import': 'Import Test Cases',
  'testCase.delete.confirm': 'Are you sure you want to delete this test case?',
  'testCase.delete.error': 'Failed to delete test case',
  'testCase.delete.success': 'Test case deleted',
  'testCase.create.advanced': 'More Options',
  'testCase.create.difficulty.label': 'Difficulty',
  'testCase.edit.error': 'Failed to update test case',
  'testCase.edit.success': 'Test case updated successfully',
  'testCase.edit.title': 'Edit Test Case',
  'testCase.create.error': 'Failed to add test case',
  'testCase.create.expected.label': 'Expected Output',
  'testCase.create.expected.placeholder': 'Enter the expected answer',
  'testCase.create.expected.required': 'Please enter the expected output',
  'testCase.create.input.label': 'Input',
  'testCase.create.input.placeholder': 'Enter the test case input or question',
  'testCase.create.success': 'Test case added successfully',
  'testCase.create.tags.label': 'Tags',
  'testCase.create.tags.placeholder': 'Comma-separated tags (optional)',
  'testCase.create.title': 'Add Test Case',
  'testCase.empty.description': 'Import or manually add test cases to this dataset',
  'testCase.empty.title': 'No test cases yet',
  'testCase.preview.expected': 'Expected',
  'testCase.preview.input': 'Input',
  'testCase.preview.title': 'Test Case Preview',
  'testCase.search.placeholder': 'Search cases...',
};
